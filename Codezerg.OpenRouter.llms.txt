LIBRARY: Codezerg.OpenRouter
LANGUAGE: C#
TARGET_FRAMEWORK: netstandard2.0
DESCRIPTION: Full reference for strongly‑typed .NET client to OpenRouter’s LLM API.

================================================
NAMESPACE: Codezerg.OpenRouter
------------------------------------------------
CLASS: OpenRouterClient : IDisposable
  CTORS:
    - OpenRouterClient(OpenRouterClientOptions opts)
    - OpenRouterClient(OpenRouterClientOptions opts, HttpClient? client)
  PROPERTY:
    - Configuration : OpenRouterClientOptions (clone, immutable)
  METHODS:
    - Task<ChatResponse> SendChatCompletionAsync(ChatRequest req,CancellationToken ct=default)
    - IAsyncEnumerable<ChatResponse> StreamChatCompletionAsync(ChatRequest req,CancellationToken ct=default)
    - Task<List<Activity>> GetActivityAsync(string? date=null,CancellationToken ct=default)
    - Task<Credits> GetCreditsAsync(CancellationToken ct=default)
    - Task<List<ProviderInfo>> GetProvidersAsync(CancellationToken ct=default)
    - Task<List<ModelInfo>> GetModelsAsync(string? category=null,CancellationToken ct=default)
    - Task<List<ModelInfo>> GetUserModelsAsync(CancellationToken ct=default)
    - Task<ModelEndpoints> GetModelEndpointsAsync(string author,string slug,CancellationToken ct=default)
    - Task<GenerationDetails> GetGenerationAsync(string id,CancellationToken ct=default)
    - void Dispose()

CLASS: OpenRouterClientOptions
  ApiKey, Endpoint, DefaultModel, Timeout, UserAgent, Referer, EnableDebugLogging

STATIC CLASS: OpenRouterClientOptionsExtensions
  - Validate()
  - Clone()
  - WithApiKey,WithEndpoint,WithDefaultModel,WithTimeout,WithUserAgent,WithReferer,WithEnableDebugLogging

CLASS: OpenRouterFrontendClient (experimental, private API discovery)
  - GetProvidersAsync(), GetModelsAsync(), FindModelsAsync(), GetModelStatsAsync()
  - GetModelsByProviderAsync(), GetModelsByModalityAsync()
  - GetReasoningModelsAsync(), GetFreeModelsAsync()
  - GetByokProvidersAsync(), GetPrivacyFriendlyProvidersAsync()

================================================
NAMESPACE: Codezerg.OpenRouter.Models
------------------------------------------------
RESPONSE WRAPPERS:
- ActivityResponse { Data: List<Activity> }
- CreditsResponse { Data: Credits }
- ProvidersResponse { Data: List<ProviderInfo> }
- ModelsResponse { Data: List<ModelInfo> }
- ModelEndpointsResponse { Data: ModelEndpoints }
- GenerationDetailsResponse { Data: GenerationDetails }

------------------------------------------------
CLASS: Activity
  - Date, Model, ModelPermaslug, EndpointId, ProviderName
  - Usage, ByokUsageInference
  - Requests, PromptTokens, CompletionTokens, ReasoningTokens

CLASS: Credits
  - TotalCredits, TotalUsage

CLASS: ProviderInfo
  - Name, Slug, PrivacyPolicyUrl, TermsOfServiceUrl, StatusPageUrl

CLASS: ModelInfo
  - Id, Name, Created, Description
  - Architecture: ModelArchitecture { InputModalities[], OutputModalities[], Tokenizer, InstructType }
  - TopProvider: TopProviderInfo { IsModerated, ContextLength?, MaxCompletionTokens? }
  - Pricing: ModelPricing { Prompt, Completion, Image, Request, WebSearch, InternalReasoning, InputCacheRead, InputCacheWrite }
  - CanonicalSlug, ContextLength, HuggingFaceId
  - PerRequestLimits: dict, SupportedParameters

CLASS: ModelEndpoints
  - Id, Name, Created, Description?, Architecture?, Endpoints: List<EndpointInfo>
  CLASS EndpointInfo { Name, ContextLength?, Pricing?, ProviderName?, SupportedParameters[], Quantization?, MaxCompletionTokens?, MaxPromptTokens?, Status?, UptimeLast30m? }
  CLASS EndpointPricing { Request?, Image?, Prompt?, Completion? }

CLASS: GenerationDetails
  - Id, TotalCost, CreatedAt, Model, Origin?, Usage, IsByok
  - UpstreamId?, CacheDiscount?, UpstreamInferenceCost, AppId?, Streamed, Cancelled
  - ProviderName?, Latency, ModerationLatency?, GenerationTime
  - FinishReason?, NativeFinishReason?
  - TokensPrompt, TokensCompletion, NativeTokensPrompt, NativeTokensCompletion, NativeTokensReasoning
  - NumMediaPrompt?, NumMediaCompletion, NumSearchResults?
  - NativeTokensCached?, NativeTokensCompletionImages?
  - ExternalUser?, ApiType?

------------------------------------------------
CLASS: ChatMessage
  - Role: ChatRole
  - Content: List<MessagePart> (converter supports string or array)
  - Name?, ToolCalls?, ToolCallId?, Images?
  FACTORY METHODS: User(), Assistant(), System(), Tool()
  BUILDERS: WithName(), WithToolCalls(), WithImages(), AddText(), AddImage(), AddAudio()
  HELPERS (JsonIgnore): FirstTextContent, CombinedTextContent, HasImages, HasAudio, IsMultimodal, IsToolResponse, HasToolCalls

CLASS: ChatRequest
  - Messages?, Prompt?, Model?, ResponseFormat?, Stop?, Stream?, MaxTokens?
  - Temperature?, TopP?, TopK?, Seed?, FrequencyPenalty?, PresencePenalty?, RepetitionPenalty?
  - LogitBias?, Logprobs?, TopLogprobs?, MinP?, TopA?
  - Prediction?, Transforms?, Models?, Route?, Provider?, User?, Modalities?, ParallelToolCalls?, Verbosity?

CLASS: ChatResponse
  - Id, Choices: List<ChatChoice>, Created, Model, Object:ObjectType, SystemFingerprint?, Usage?, Error?

CLASS: ChatChoice
  - Index, FinishReason?, NativeFinishReason?, Error?
  - Message: ChatMessage? (non‑stream)
  - Delta: ChatDelta? (streaming, incremental)
  - Text?

CLASS: ChatDelta { Content?, Role?, ToolCalls[], Images[] }
CLASS: TokenUsage { PromptTokens, CompletionTokens, TotalTokens, CacheCreationInputTokens?, CacheReadInputTokens? }

------------------------------------------------
ERROR MODEL:
- ApiError { Code:int, Message:string, Metadata? }
- ModerationErrorDetails { Reasons[], FlaggedInput, ProviderName, ModelSlug }
- ProviderErrorDetails { ProviderName, Raw? }

------------------------------------------------
CONTENT PARTS:
CLASS: MessagePart { Type:MessageContentType, Text?, ImageUrl?, InputAudio? }
  FACTORY: CreateText(), CreateImage(url,detail?), CreateAudio(data,format)
  HELPERS: IsText, IsImage, IsAudio
CLASS: ImageReference { Url, Detail? }
CLASS: AudioContent { Data, Format="wav" }
CLASS: GeneratedImage { Type="image_url", ImageUrl:GeneratedImageReference }
CLASS: GeneratedImageReference { Url }

------------------------------------------------
TOOL SYSTEM:
CLASS: ToolDefinition { Type=ToolType, Function:FunctionDescription }
CLASS: FunctionDescription { Name, Description?, Parameters:JObject? }
CLASS: ToolCall { Id, Type, Function(FunctionCall { Name, Arguments }) }
CLASS: ToolChoice { Type, Function:ToolChoiceDetails{Name} }

------------------------------------------------
CONFIG / ROUTING:
CLASS: ProviderOptions { AllowFallbacks?, RequireParameters?, DataCollection?, Order[], Ignore[], Allow[], Block[] }
CLASS: ResponseFormatOptions { Type:ResponseFormatType, JsonSchema? }
CLASS: PredictionOptions { Type=PredictionType.Content, Content:string }

------------------------------------------------
ENUM-LIKE RECORDS:
- ChatRole (system,user,assistant,tool)
- CompletionFinishReason (stop,length,tool_calls,content_filter,error)
- MessageContentType (text,image_url,input_audio)
- Modality (text,image,audio)
- ResponseFormatType (json_object,json_schema,content)
- ToolType (function)
- DataCollectionOption (allow,deny)
- PredictionType (content)
- VerbosityLevel (low,medium,high)
- ObjectType ("chat.completion", "chat.completion.chunk")

================================================
NAMESPACE: Codezerg.OpenRouter.Frontend  (Experimental API DTOs)
------------------------------------------------
CLASS: FrontendModel { Slug,HfSlug,Name,ShortName,Author,Description,ContextLength,InputModalities[],OutputModalities[],HasTextOutput,Group,InstructType,DefaultSystem,DefaultStops[],Hidden,Permaslug,ReasoningConfig?, Endpoint? }
CLASS: ReasoningConfig { StartToken, EndToken, SystemPrompt }
CLASS: ModelEndpoint { Id,Name,ContextLength,ModelVariantSlug,ModelVariantPermaslug,ProviderName,ProviderSlug,Pricing,VariablePricings[],SupportedParameters[],IsFree,CanAbort,MaxPromptTokens?,MaxCompletionTokens?,SupportsReasoning,SupportsMultipart,SupportsToolParameters,LimitRpm?,LimitRpd?,Stats?,Features? }
CLASS: ModelPricing { Prompt,Completion,Image,Request,WebSearch,InternalReasoning,ImageOutput }
CLASS: VariablePricing { Type,Threshold,Request }
CLASS: ModelStats { EndpointId,P50Throughput,P50Latency,RequestCount }
CLASS: ModelFeatures { SupportsToolChoice, ReasoningConfig }
CLASS: ToolChoiceSupport { LiteralNone, LiteralAuto, LiteralRequired, TypeFunction }

CLASS: FrontendModelResponse { Data: object (either array of FrontendModel or FrontendModelData) }
CLASS: FrontendModelData { Models: List<FrontendModel> }
CLASS: FrontendModelStatsResponse { Data: List<ModelEndpointStats> }
CLASS: ModelEndpointStats : ModelEndpoint { Model:FrontendModel, ProviderInfo:FrontendProvider, DataPolicy }

CLASS: FrontendProvider { Name, DisplayName, Slug, BaseUrl, DataPolicy, Headquarters, Datacenters[], HasChatCompletions, HasCompletions, IsAbortable, ModerationRequired, AdapterName, IsMultipartSupported, StatusPageUrl, ByokEnabled, Icon, IgnoredProviderModels[] }
CLASS: DataPolicy { Training, RetainsPrompts, RetentionDays?, CanPublish, TermsOfServiceUrl, PrivacyPolicyUrl, RequiresUserIds? }
CLASS: ProviderIcon { Url, ClassName }
CLASS: FrontendProviderResponse { Data: List<FrontendProvider> }

================================================
USAGE EXAMPLES:

CHAT (non‑stream):
var req = new ChatRequest{ Messages=new(){ ChatMessage.User("Capital of France?") }};
var resp = await client.SendChatCompletionAsync(req);
Console.WriteLine(resp.Choices[0].Message?.FirstTextContent);

STREAMING TEXT:
await foreach(var chunk in client.StreamChatCompletionAsync(req)){
 var token = chunk.Choices[0].Delta?.Content;
 if(!string.IsNullOrEmpty(token)) Console.Write(token);
}

STREAMING TOOL CALL:
await foreach(var chunk in client.StreamChatCompletionAsync(req)){
 if(chunk.Choices[0].Delta?.ToolCalls?.Count > 0){
    foreach(var call in chunk.Choices[0].Delta.ToolCalls)
       Console.WriteLine($"ToolCall: {call.Function.Name} {call.Function.Arguments}");
 }
}

MULTIMODAL:
var msg=new ChatMessage(ChatRole.User).AddText("Describe this").AddImage("https://example.com/cat.jpg");
var resp=await client.SendChatCompletionAsync(new ChatRequest{Messages=new(){msg}});
Console.WriteLine(resp.Choices[0].Message?.FirstTextContent);

STRUCTURED JSON OUTPUT:
var req=new ChatRequest{
 Messages=new(){ChatMessage.User("Generate name and age")},
 ResponseFormat=new ResponseFormatOptions{Type=ResponseFormatType.JsonSchema,JsonSchema=new{type="object",properties=new{name=new{type="string"},age=new{type="integer"}}}}};
var resp=await client.SendChatCompletionAsync(req);
Console.WriteLine(resp.Choices[0].Message?.FirstTextContent);

================================================
BEST PRACTICES:
- Set ApiKey, UserAgent, Referer in options (required by OpenRouter).  
- If no Model specified → DefaultModel is used.  
- Builders (AddText/AddImage/AddAudio) ensure valid multimodal message parts.  
- Streaming vs Non‑streaming difference: Delta vs Message.  
- Handle ToolCalls before continuing conversation.  
- Use ResponseFormatOptions for schema-enforced JSON outputs.  
- `Configuration` is immutable → prepare via *With* extensions before constructing client.  
- For large/multi‑user apps, clone options for variations per client.  
- Expect ApiError at root response or inside choices.  
- Treat OpenRouterFrontendClient as experimental/private.